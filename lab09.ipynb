{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsITBHLCFCnJ"
   },
   "source": [
    "# Wstęp\n",
    "Zadanie 9 stanowi pierwszy z trzech etapów zajęć poświęconych sieciom rekurencyjnym i predykcji z wykorzystaniem danych multimodalnych. Efektem wszystkich trzech etapów będzie sieć rekurencyjna z warstwą atencji do predykcji kursu kryptowaluty Bitcoin (BTC) w oparciu o dane z giełdy oraz o wyniki analizy emocji komunikatów z mediów społecznościowych, do których również należy utworzyć dedykowany model sieci rekurencyjnej. Plan realizacji etapów wygląda następująco:\n",
    "\n",
    "1.   EmoTweet - model sieci rekurencyjnej do analizy emocji \n",
    "2.   MultiBTC - multimodalny model sieci rekurencyjnej do predykcji kursu BTC\n",
    "3.   AttEmoTweet & AttMultiBTC - rozszerzenie modeli EmoTweet i MultiBTC o warstwę atencji \n",
    "\n",
    "Każdy etap jest traktowany jako oddzielna lista na laboratorium, za którą można otrzymać 10 punktów. \n",
    "\n",
    "# Cel ćwiczenia\n",
    "\n",
    "Celem pierwszego etapu prac jest zapoznanie się z podstawową siecią rekurencyjną LSTM. Ze względu na fakt, że model ten będzie wykorzystany do analizy emocji tekstu, w ramach teorii do zadania zostanie omówiony podstawowy mechanizm konwersji słów w tekście do postaci wektorów dystrybucyjnych (tzw. word embeddings) na podstawie rozwiązania o nazwie `fastText`. Modele będą budowane na ogólnodostępnym zbiorze `TweetEval`, zawierającym podzbiory ręcznie anotowanych tweetów przy pomocy etykiet odnoszących się do następujących zjawisk: 1) emocje (emotion), 2) emotikony (emoji), 3) ironia (irony), 4) mowa nienawiści (hate speech), 5) mowa ofensywna (offensive language), 6) wydźwięk (sentiment), 7) nastawienie (stance). \n",
    "\n",
    "# Warunki zaliczenia\n",
    "\n",
    "Do zaliczenia pierwszego etapu należy utworzyć następujące modele dla min. 2 wybranych zjawisk:\n",
    "\n",
    "1.   Model bazowy (regresja logistyczna).\n",
    "2.   Model rekurencyjny oparty o sieć LSTM.\n",
    "\n",
    "Wytrenowane modele będą wykorzystane w 2 etapie, dlatego proszę je zachować.\n",
    "\n",
    "# Wektory dystrybucyjne\n",
    "\n",
    "W przetwarzaniu języka naturalnego, o wektorach dystrybucyjnych (inaczej osadzeniach lub zanurzeniach, ang. word embeddings) mówi się w kontekście reprezentacji słów w tekście, zazwyczaj w postaci wektora liczb rzeczywistych, który koduje znaczenie słowa. Hipoteza dystrybucyjna, u podstawy której leży większość metod reprezentacji, mówi o tym, że słowa, które często współwystępują, mają podobne znaczenie. Wektory dystrybucyjne można uzyskać za pomocą zestawu technik modelowania języka, w których słowa lub frazy są mapowane do wektorów liczb rzeczywistych. Z reguły polega to na matematycznym zanurzeniu z przestrzeni o wielu wymiarach opisujących słowo (konteksty) do ciągłej przestrzeni wektorowej o znacznie mniejszym wymiarze.\n",
    "\n",
    "Metody generowania tego odwzorowania obejmują sieci neuronowe, redukcję wymiarowości na macierzy współwystępowania słów, modele probabilistyczne lub jawną reprezentację w kontekście, w którym pojawiają się słowa. Wektory dystrybucyjne, używane jako podstawowa reprezentacja wejściowa tekstu, okazały się istotnie poprawiać jakość w wielu zadaniach NLP, takich jak np. rozpoznawanie nazw własnych, określanie części mowy, rozpoznawanie dziedziny tekstu, czy też rozpoznawanie wydźwięku i emocji w tekście. \n",
    "\n",
    "# fastText\n",
    "\n",
    "[fastText](https://fasttext.cc/) jest biblioteką do efektywnego uczenia modeli reprezentacji wektorowych słów oraz do budowania klasyfikatorów tekstu. Modele językowe można budować z wykorzystaniem dwóch popularnych technik: [Continuous Bag of Words](https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-cbow.html) oraz [Skip-Gram](https://towardsdatascience.com/skip-gram-nlp-context-words-prediction-algorithm-5bbf34f84e0c). \n",
    "\n",
    "## Instalacja\n",
    "\n",
    "Pobranie repozytorium projektu:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UkMDUx6bn6e",
    "outputId": "3f590583-7442-4775-b0f4-10811059b878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'fastText' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JWc5Ie0cvYo"
   },
   "source": [
    "Instalacja biblioteki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ku0F_kKMbteg",
    "outputId": "550c417b-5d76-4ce3-8b9a-af4b8be0355f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘build’: File exists\n"
     ]
    }
   ],
   "source": [
    "!cd fastText && mkdir build && cd build && cmake ..  && make && make install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ApV6Bzwc1_R"
   },
   "source": [
    "Instalacja API do Pythona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xElxRxJycnDA",
    "outputId": "2e4087df-af7f-4552-f192-0398258c0fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/fastText\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (2.6.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (56.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.2) (1.19.5)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3086318 sha256=fa0f65d0fcf7521ac505b7ed8621fff2863a5ce2ec81d1a97d12e597f1cb6393\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-h4yx9p74/wheels/a1/9f/52/696ce6c5c46325e840c76614ee5051458c0df10306987e7443\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "  Found existing installation: fasttext 0.9.2\n",
      "    Uninstalling fasttext-0.9.2:\n",
      "      Successfully uninstalled fasttext-0.9.2\n",
      "Successfully installed fasttext-0.9.2\n"
     ]
    }
   ],
   "source": [
    "!cd fastText && pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ceW8c2XdOf4"
   },
   "source": [
    "# Dane do etapu nr 1\n",
    "\n",
    "## Korpus \n",
    "Korpus (zbiór dokumentów) do realizacji etapu nr 1 pochodzą z repozytorium [TweetEval](https://github.com/cardiffnlp/tweeteval). Repozytorium zawiera 7 różnorodnych zbiorów danych, zawierających zanonimizowane wpisy z [Twittera](https://twitter.com), anotowane następującymi zjawiskami: 1) emocje (emotion), 2) emotikony (emoji), 3) ironia (irony), 4) mowa nienawiści (hate speech), 5) mowa ofensywna (offensive language), 6) wydźwięk (sentiment), 7) nastawienie (stance). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ER8c8zNmgE40",
    "outputId": "e06634cd-5299-472b-a58e-79ed4502ee48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-09 15:38:07--  http://jankocon.clarin-pl.eu/share/tweeteval.7z\n",
      "Resolving jankocon.clarin-pl.eu (jankocon.clarin-pl.eu)... 156.17.135.34\n",
      "Connecting to jankocon.clarin-pl.eu (jankocon.clarin-pl.eu)|156.17.135.34|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17390348 (17M) [application/x-7z-compressed]\n",
      "Saving to: ‘tweeteval.7z.1’\n",
      "\n",
      "tweeteval.7z.1      100%[===================>]  16.58M   604 B/s    in 18s     \n",
      "\n",
      "2021-05-09 15:38:25 (968 KB/s) - ‘tweeteval.7z.1’ saved [17390348/17390348]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://jankocon.clarin-pl.eu/share/tweeteval.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qS6VxC26gUNt",
    "outputId": "0b50d194-3d20-4789-9082-40b9b9511079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 17390348 bytes (17 MiB)\n",
      "\n",
      "Extracting archive: tweeteval.7z\n",
      "--\n",
      "Path = tweeteval.7z\n",
      "Type = 7z\n",
      "Physical Size = 17390348\n",
      "Headers Size = 1810\n",
      "Method = LZMA2:24\n",
      "Solid = +\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b\n",
      "Would you like to replace the existing file:\n",
      "  Path:     ./tweeteval/.git/HEAD\n",
      "  Size:     21 bytes (1 KiB)\n",
      "  Modified: 2021-04-09 11:24:03\n",
      "with the file from archive:\n",
      "  Path:     tweeteval/.git/HEAD\n",
      "  Size:     21 bytes (1 KiB)\n",
      "  Modified: 2021-04-09 11:24:03\n",
      "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? y\n",
      "\n",
      " 10% 33 - tweeteval/.git/HEAD\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Would you like to replace the existing file:\n",
      "  Path:     ./tweeteval/.git/config\n",
      "  Size:     264 bytes (1 KiB)\n",
      "  Modified: 2021-04-09 11:24:03\n",
      "with the file from archive:\n",
      "  Path:     tweeteval/.git/config\n",
      "  Size:     264 bytes (1 KiB)\n",
      "  Modified: 2021-04-09 11:24:03\n",
      "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? y\n",
      "\n",
      " 10% 34 - tweeteval/.git/config\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Would you like to replace the existing file:\n",
      "  Path:     ./tweeteval/.git/description\n",
      "  Size:     73 bytes (1 KiB)\n",
      "  Modified: 2021-04-09 11:24:00\n",
      "with the file from archive:\n",
      "  Path:     tweeteval/.git/description\n",
      "  Size:     73 bytes (1 KiB)\n",
      "  Modified: 2021-04-09 11:24:00\n",
      "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? y\n",
      "\n",
      " 10% 35 - tweeteval/.git/description\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Would you like to replace the existing file:\n",
      "  Path:     ./tweeteval/.git/hooks/applypatch-msg.sample\n",
      "  Size:     478 bytes (1 KiB)\n",
      "  Modified: 2021-04-09 11:24:00\n",
      "with the file from archive:\n",
      "  Path:     tweeteval/.git/hooks/applypatch-msg.sample\n",
      "  Size:     478 bytes (1 KiB)\n",
      "  Modified: 2021-04-09 11:24:00\n",
      "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? s\n",
      "\n",
      " 10% 36 . tweeteval/.git/hooks/applypatch-msg.sample\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 79 . tweeteval/datasets/hate/train_text.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Folders: 33\n",
      "Files: 115\n",
      "Size:       30563155\n",
      "Compressed: 17390348\n"
     ]
    }
   ],
   "source": [
    "!7za x tweeteval.7z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kb6c5nuvgiaF"
   },
   "source": [
    "## Zawartość korpusu\n",
    "\n",
    "W katalogu głównym (tweeteval) znajdują się następujące elementy:\n",
    "*   `datasets` - katalog ze zbiorami danych\n",
    "   * `emotion` - tweety anotowane emocjami \n",
    "     * `mapping.txt` - identyfikatory etykiet oraz ich opis\n",
    "     * `train_text.txt` - wpisy z Twittera (część ucząca)\n",
    "     * `train_labels.txt` - etykiety wpisów z Twittera (część ucząca)\n",
    "     * `test_*.txt, valid_*.txt` - j.w. (część testowa i walidacyjna)\n",
    "   * `emoji` - tweety anotowane emotikonami\n",
    "   * `...` - katalogi zawierające tweety anotowane pozostałymi zjawiskami\n",
    "*   `predictions` - katalog z przykładowymi predykcjami\n",
    "   * `emotion.txt` - etykiety modelu predykcyjnego dla części testowej danych `emotion`\n",
    "   * `emoji.txt` - j.w. dla cz. testowej danych `emoji`\n",
    "   * `...` - j.w. dla pozostałych danych\n",
    "*   `evaluation_script.py` - skrypt do ewaluacji \n",
    "\n",
    "## Model języka\n",
    "\n",
    "Na potrzeby zadania został przygotowany model Skip-Gram reprezentacji wektorowej słów, zbudowany na wielkim korpusie tweetów dotyczących kursu BTC. Wersja binarna tego modelu dostępna jest w 2 wariantach:\n",
    "* [wektory 100-elementowe (1.7GB)](http://jankocon.clarin-pl.eu/share/fasttext_tweetmodel_btc_sg_100_en.bin)\n",
    "* [wektory 20-elementowe (350MB)](http://jankocon.clarin-pl.eu/share/fasttext_tweetmodel_btc_sg_20_en.bin)\n",
    "\n",
    "Na potrzeby prezentacji przykładowego rozwiązania zostanie wykorzystany mniejszy model. Do realizacji ostatecznego rozwiązania należy wykorzystać większy model. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stk-sYt9o6sD"
   },
   "source": [
    "# Model bazowy rozpoznawania emocji\n",
    "\n",
    "Model bazowy, zbudowany z wykorzystaniem narzędzia fastText (oparty o regresję logistyczną), będzie punktem wyjścia do porównania się z modelami opartymi o sieci LSTM, których skonstruowanie i ewaluacja na wybranych zadaniach będzie celem etapu nr 1. \n",
    "\n",
    "Pobranie mniejszego modelu reprezentacji języka tweetów:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChAehfcHggvF",
    "outputId": "609191cb-d759-4fe6-f395-f8e3be6e2ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-09 15:59:23--  http://jankocon.clarin-pl.eu/share/fasttext_tweetmodel_btc_sg_20_en.bin\n",
      "Resolving jankocon.clarin-pl.eu (jankocon.clarin-pl.eu)... 156.17.135.34\n",
      "Connecting to jankocon.clarin-pl.eu (jankocon.clarin-pl.eu)|156.17.135.34|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 365240858 (348M) [application/octet-stream]\n",
      "Saving to: ‘fasttext_tweetmodel_btc_sg_20_en.bin.1’\n",
      "\n",
      "fasttext_tweetmodel 100%[===================>] 348.32M  10.9MB/s    in 34s     \n",
      "\n",
      "2021-05-09 15:59:57 (10.2 MB/s) - ‘fasttext_tweetmodel_btc_sg_20_en.bin.1’ saved [365240858/365240858]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://jankocon.clarin-pl.eu/share/fasttext_tweetmodel_btc_sg_20_en.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkacglPdr96Y"
   },
   "source": [
    "Wydobycie słownika wektorów z binarnego modelu języka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "CHyqkncyrZru"
   },
   "outputs": [],
   "source": [
    "!python fastText/python/doc/examples/bin_to_vec.py fasttext_tweetmodel_btc_sg_20_en.bin > fasttext_tweetmodel_btc_sg_20_en.vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E_5UDKYyzwp"
   },
   "source": [
    "Dodanie prefiksu `__label__` do etykiet zbioru `emotion`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "OjUQvyKIsKV8"
   },
   "outputs": [],
   "source": [
    "!sed 's/^/__label__/g' tweeteval/datasets/emotion/train_labels.txt > train_labels_emo.txt\n",
    "!sed 's/^/__label__/g' tweeteval/datasets/emotion/test_labels.txt > test_labels_emo.txt\n",
    "!sed 's/^/__label__/g' tweeteval/datasets/emotion/val_labels.txt > val_labels_emo.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlHv_VJ5zIHw"
   },
   "source": [
    "Przygotowanie zbioru uczącego, testowego i walidacyjnego w formacie `fastText`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "nNdjvsT8siZ1"
   },
   "outputs": [],
   "source": [
    "!paste -d \" \" tweeteval/datasets/emotion/train_text.txt train_labels_emo.txt > train_emo.txt\n",
    "!paste -d \" \" tweeteval/datasets/emotion/test_text.txt test_labels_emo.txt > test_emo.txt\n",
    "!paste -d \" \" tweeteval/datasets/emotion/val_text.txt val_labels_emo.txt > val_emo.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ro5A5HAEzGNJ"
   },
   "source": [
    "Trenowanie modelu z wykorzystaniem wejścia `train_emo.txt`, z określeniem wyjściowej nazwy modelu `emo_model`, dla wektorów słów o wymiarze `20`, z wykorzystaniem pretrenowanych wektorów z pliku `fasttext_tweetmodel_btc_sg_20_en.vec` i z uruchomieniem dostrajania hiperparametrów na zbiorze walidacyjnym `val_emo.txt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GChCYj1ptoEj",
    "outputId": "732c80ab-9de3-4749-bd2e-330a212db5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : dim is manually set to a specific value. It will not be automatically optimized.\n",
      "Progress: 100.0% Trials:   22 Best score:  0.689840 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 0M words\n",
      "Number of words:  12887\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread:   77277 lr:  0.000000 avg.loss:  0.529891 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "!fasttext supervised -input train_emo.txt -output emo_model -dim 20 -pretrainedVectors fasttext_tweetmodel_btc_sg_20_en.vec -autotune-validation val_emo.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkp4BDnvzxrN"
   },
   "source": [
    "Podstawowa ewaluacja modelu z wykorzystaniem `fastText`, wynikiem jest precyzja (P - precision) i kompletność (R - recall) w wariancie [weighted](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90GbSCCgvmCj",
    "outputId": "97a7609c-0ed4-4ca8-94f1-d7f8ac4a1915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t1421\n",
      "P@1\t0.69\n",
      "R@1\t0.69\n"
     ]
    }
   ],
   "source": [
    "!fasttext test emo_model.bin test_emo.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoqaR5To0UWq"
   },
   "source": [
    "Rozszerzona ewaluacja modelu z wykorzystaniem `fastText`, wynikiem jest precyzja (P - precision), kompletność (R - recall) oraz F1-score dla każdej etykiety w wariancie [weighted](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3xFd-RDwv_w",
    "outputId": "966ee654-9054-4c84-f06d-245d0be8297d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score : 0.760887  Precision : 0.702580  Recall : 0.829749   __label__0\n",
      "F1-Score : 0.677043  Precision : 0.670951  Recall : 0.683246   __label__3\n",
      "F1-Score : 0.661538  Precision : 0.736301  Recall : 0.600559   __label__1\n",
      "F1-Score : 0.411765  Precision : 0.518519  Recall : 0.341463   __label__2\n",
      "N\t1421\n",
      "P@1\t0.690\n",
      "R@1\t0.690\n"
     ]
    }
   ],
   "source": [
    "!fasttext test-label emo_model.bin test_emo.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y__FOjZO0jrw"
   },
   "source": [
    "Przygotowanie danych do ewaluacji z wykorzystaniem skryptu dołączonego do zbioru TweetEval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZyri0pVw43n",
    "outputId": "41a3087b-9390-4deb-e885-690f1ae1f255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘predictions2’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "1gMgdnILxScS"
   },
   "outputs": [],
   "source": [
    "!fasttext predict emo_model.bin tweeteval/datasets/emotion/test_text.txt | sed 's/__label__//g' > predictions2/emotion.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRwh9aIx0s3I"
   },
   "source": [
    "Uruchomienie ewaluacji. Oprócz wyników P, R, F1 [weighted]((https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)) dla każdej etykiety, otrzymujemy również wyniki w wariancie [macro]((https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)). **Ostateczną miarą (TweetEval Score) jest miara F1-score w wariancie macro i tę miarę proszę traktować jako kluczową przy porównywaniu rozwiązań.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpAjMNr2xn-e",
    "outputId": "61e3242c-d253-44e0-82ab-cb2281534557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'precision': 0.7025796661608498, 'recall': 0.8297491039426523, 'f1-score': 0.76088742810189, 'support': 558}\n",
      "1 {'precision': 0.7363013698630136, 'recall': 0.6005586592178771, 'f1-score': 0.6615384615384615, 'support': 358}\n",
      "2 {'precision': 0.5185185185185185, 'recall': 0.34146341463414637, 'f1-score': 0.411764705882353, 'support': 123}\n",
      "3 {'precision': 0.6709511568123393, 'recall': 0.6832460732984293, 'f1-score': 0.6770428015564202, 'support': 382}\n",
      "accuracy 0.6903589021815623\n",
      "macro avg {'precision': 0.6570876778386803, 'recall': 0.6137543127732763, 'f1-score': 0.6278083492697812, 'support': 1421}\n",
      "weighted avg {'precision': 0.6866407204847322, 'recall': 0.6903589021815623, 'f1-score': 0.6830987777126711, 'support': 1421}\n",
      "------------------------------\n",
      "TweetEval Score (emotion): 0.6278083492697812\n"
     ]
    }
   ],
   "source": [
    "!python tweeteval/evaluation_script.py --tweeteval_path tweeteval/datasets --predictions_path predictions2 --task emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FV9_Gnrz2T0m"
   },
   "source": [
    "# Budowa modeli EmoTweet\n",
    "\n",
    "W tej sekcji Państwa zadaniem będzie przygotowanie modeli sieci LSTM oraz modeli bazowych opartych o regresję logistyczną (fastText) dla wybranych 2 zjawisk ze zbioru TweetEval. Dla sieci LSTM kolejne jednostki sieci rekurencyjnej na wejściu dostają reprezentację wektorową kolejnych wyrazów w tekście. Wyjście z ostatniej jednostki podlega klasyfikacji. W celu usprawnienia zadania, przedstawiona zostanie metoda reprezentacji wektorowej tekstu z wykorzystaniem Pythonowego API do narzędzia fastText. Do ewaluacji modeli należy wykorzystać uprzednio zaprezentowany skrypt `tweeteval/evaluation_script.py`.\n",
    "\n",
    "## Wektoryzacja tekstu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pmdakZza43X8"
   },
   "outputs": [],
   "source": [
    "# inicjalizacja biblioteki\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DpJZYWyd6EK-"
   },
   "outputs": [],
   "source": [
    "# ładowanie modelu\n",
    "MODEL_PATH = 'fasttext_tweetmodel_btc_sg_20_en.bin'\n",
    "model = fasttext.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "yRs60cO96zk5",
    "outputId": "a1d7f43f-2f51-4f29-b121-a3c870689dfc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>I get discouraged because I try for 5 fucking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>The @user are in contention and hosting @user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>@user @user @user @user @user as a fellow UP g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>You have a #problem? Yes! Can you do #somethin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>@user @user i will fight this guy! Don't insul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3257 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     “Worry is a down payment on a problem you may ...\n",
       "1     My roommate: it's okay that we can't spell bec...\n",
       "2     No but that's so cute. Atsu was probably shy a...\n",
       "3     Rooneys fucking untouchable isn't he? Been fuc...\n",
       "4     it's pretty depressing when u hit pan on ur fa...\n",
       "...                                                 ...\n",
       "3252  I get discouraged because I try for 5 fucking ...\n",
       "3253  The @user are in contention and hosting @user ...\n",
       "3254  @user @user @user @user @user as a fellow UP g...\n",
       "3255  You have a #problem? Yes! Can you do #somethin...\n",
       "3256  @user @user i will fight this guy! Don't insul...\n",
       "\n",
       "[3257 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wczytanie danych treningowych\n",
    "import pandas as pd\n",
    "TRAIN_PATH = 'tweeteval/datasets/emotion/train_text.txt'\n",
    "train_texts = pd.read_csv(TRAIN_PATH, sep='\\t', header=None)\n",
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fk-7nV9x8C-Y",
    "outputId": "df76b642-a3c9-41d7-e10a-21c19dd187de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Worry -1 [-0.04189867  0.15429688  0.96717507  1.3809655   0.49123076 -0.5447607\n",
      " -0.11276884  0.20356484 -1.0640966  -1.6616327   0.03930127 -0.7224096\n",
      "  0.21334486 -0.5872285   0.2898182   0.81751084 -1.6077403   1.8038087\n",
      "  0.4850348   1.0643197 ]\n",
      "is 6 [ 0.24099417  0.13544752  0.7251924   0.32544732  0.27421224  0.31903243\n",
      "  0.7501186   0.22853182 -0.91543657  0.08587569  0.13866538 -0.38624704\n",
      " -0.30637258  0.13666666 -0.43992838 -0.12443608 -1.0383893  -0.06567164\n",
      "  0.17007533 -0.16708991]\n",
      "a 7 [-0.00810981 -0.03934941  0.81658655  0.56301105  0.43812367  0.29547286\n",
      "  0.4691784   0.07483605 -0.58705056  0.28240088 -0.6339584  -0.16187707\n",
      " -0.23376046 -0.1245347   0.03071329 -0.07603034 -0.9066614  -0.07007706\n",
      "  0.4522892  -0.15033531]\n",
      "down 174 [ 0.9175071  -1.0815151   0.07119758  0.34226617  0.9607946   0.5973182\n",
      "  0.91058624 -0.32068744 -0.72137564  1.2241784  -0.1882128  -0.23591968\n",
      " -0.02596712 -0.10194965 -0.09553405  0.36303622  0.22354192  0.4901933\n",
      "  0.5405883   0.5965071 ]\n",
      "payment 556 [ 0.6073219  -0.00891357  0.7414747   1.3249576   0.07864746  1.4985372\n",
      "  0.4708811   1.4519942   0.13019626 -0.07420245 -0.83968335 -0.05105841\n",
      " -0.28754452  0.36899182  0.7846754  -0.891886   -0.6211444   0.49265763\n",
      " -0.11467575 -0.0749438 ]\n",
      "on 14 [-0.09723835  0.3496086   0.6910995   0.28277752  0.8975253  -0.01230987\n",
      "  0.67500156  0.02879165 -0.786506    0.602648   -0.39817798  0.543332\n",
      " -0.46127442 -0.23781577  0.0184579  -0.28403515 -0.3935916   0.3259461\n",
      "  0.0507571  -0.03765008]\n",
      "a 7 [-0.00810981 -0.03934941  0.81658655  0.56301105  0.43812367  0.29547286\n",
      "  0.4691784   0.07483605 -0.58705056  0.28240088 -0.6339584  -0.16187707\n",
      " -0.23376046 -0.1245347   0.03071329 -0.07603034 -0.9066614  -0.07007706\n",
      "  0.4522892  -0.15033531]\n",
      "problem 1224 [ 0.9236216   0.13799877  0.9784595   1.5032955   0.31760898  0.13017276\n",
      "  0.5282482   0.4380176  -0.556051    0.11004172 -0.53169626 -0.7698464\n",
      " -0.21855882  0.10204052  0.089779    0.04558972 -0.4503975  -0.40340552\n",
      "  0.1640271   0.30253166]\n",
      "you 18 [ 0.36285082  0.23824042  0.92288643  0.33069703  0.61494684  0.62680995\n",
      "  0.8206055   0.49254185 -0.44717252 -0.47944754 -0.852041   -0.63990945\n",
      "  0.02505241 -0.43478322 -0.06202105  0.16197506 -0.36003593  0.2883114\n",
      "  0.73949414  0.5215194 ]\n",
      "may 309 [-0.20453136 -0.15716666  0.2648741   0.91359925  0.8807271   0.45750532\n",
      "  0.78538996  0.15402626 -0.9378929   0.49042216 -0.3321735  -0.6558436\n",
      "  0.08917101 -0.42916426 -0.4275598   0.3072008  -0.45899373 -0.02519113\n",
      "  0.34117666  0.12960152]\n",
      "never 299 [ 0.4569879  -0.43546084  0.8783896   0.8701302   0.47704792  0.46891853\n",
      "  0.77218413  0.28471166 -0.35907164 -0.17841178 -0.6685155  -1.0739613\n",
      "  0.17042854 -0.6416858  -0.0809866   0.52535385 -0.38173252  0.22777203\n",
      "  0.5776487   0.47688836]\n",
      "have'. -1 [-0.14791821  0.27410123  0.6040076   1.4533241   0.27587754  0.37697735\n",
      "  0.8350882   0.08774029 -0.9036173  -0.12468915 -0.8917518  -0.99509364\n",
      " -0.1603566  -0.50394845 -0.6500326   0.21711075 -0.20765467  0.57654476\n",
      "  0.976134   -0.09989043]\n",
      " Joyce -1 [ 0.3620899  -0.21890068  0.6421599   0.4646088  -0.23233397  0.01426617\n",
      "  0.75234526  0.06882509 -0.7289002   0.84054786 -0.8729406  -0.38942376\n",
      " -0.813916    0.52664775 -0.22176157  0.6487463  -0.97409683  1.1249645\n",
      " -0.6657481  -0.39433447]\n",
      "Meyer. 512882 [ 0.21895045  0.3844226   1.1516806   0.94822884  0.27445677  0.14578705\n",
      " -0.22505678 -0.32554576  0.16166015 -0.0054998  -1.2656554  -0.60765606\n",
      " -0.70257545  1.0171603  -0.3287179   0.5872529  -0.9836187   1.2412837\n",
      "  0.30786654 -0.36381623]\n",
      "#motivation 4480 [ 0.3188765   1.6882232  -0.5868895   0.6897793   0.95900065  0.80034953\n",
      " -1.3323131   1.2530718   0.0942677   0.2178247  -2.2693706  -0.7811642\n",
      "  0.01969428 -0.19465806 -1.6017233   1.0578989  -1.521254    1.5721912\n",
      "  0.43281424  1.6291353 ]\n",
      "#leadership 11070 [ 0.804105    1.703703   -0.27683935  1.0883378   1.2486427   0.71987647\n",
      " -1.2214324   0.31226104  0.28527248  0.43703973 -1.8948476  -0.66148883\n",
      "  0.5252311   0.3964793  -0.8544514   1.5619631  -1.4804806   0.9278764\n",
      " -0.8143877   1.1089797 ]\n",
      "#worry 238619 [ 1.659063   -0.08081658 -0.51301146  1.7041371   0.99064165  0.66747195\n",
      " -0.7270127   0.53979534  0.6186053  -0.26956725 -1.8310189  -1.1024348\n",
      " -0.0060048  -1.2603769  -1.9151248   0.394539   -0.64696866  1.3250468\n",
      "  0.07283593  0.45277843]\n"
     ]
    }
   ],
   "source": [
    "# wektoryzacja pierwszego tekstu\n",
    "first_text = train_texts[0][0]\n",
    "for word in fasttext.tokenize(first_text):\n",
    "  print(word, model.get_word_id(word), model.get_word_vector(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWb5iv7T9ML9"
   },
   "source": [
    "Proszę zwrócić uwagę, że fastText jest w stanie przyporządkować reprezentację wektorową nawet dla takich słów, których model języka nie widział w trakcie uczenia (pierwszy token wejściowego tekstu). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYtFNcbU9qSR"
   },
   "source": [
    "## Model klasyfikacji tekstu LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YOw5HxrpDtos"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "def read_to_dataloader(dataset_path, batch_size, train_test_or_val = 'train'):\n",
    "    assert train_test_or_val in ['train', 'test', 'val']\n",
    "    X = pd.read_csv(os.path.join(dataset_path, f'{train_test_or_val}_text.txt'), sep=' \\n', header=None)\n",
    "    y = pd.read_csv(os.path.join(dataset_path, f'{train_test_or_val}_labels.txt'), sep=' \\n', header=None)\n",
    "\n",
    "    X_tensor = nn.utils.rnn.pad_sequence([torch.Tensor([model.get_word_vector(word) for word in fasttext.tokenize(tweet)]) for tweet in X[0]], batch_first=True)\n",
    "    y_tensor = torch.Tensor(y.values).long() \n",
    "\n",
    "    return DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Zd_G_lXBRTnD"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.5):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.dense = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dense(x[:, -1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9E-pBUY90LF"
   },
   "source": [
    "\n",
    "## Trenowanie modeli LSTM dla ZJAWISKO_1 i ZJAWISKO_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1Syr87r2-tSO"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def fit(\n",
    "    model: nn.Module, \n",
    "    optimiser: optim.Optimizer, \n",
    "    loss_fn: torch.nn.CrossEntropyLoss, \n",
    "    train_dl: DataLoader, \n",
    "    val_dl: DataLoader, \n",
    "    epochs: int, \n",
    "    print_metrics: str = True\n",
    "):\n",
    "  for epoch in range(epochs):\n",
    "      model.train()\n",
    "      for X_batch, y_batch in train_dl:\n",
    "          y_pred = model(X_batch.cuda())\n",
    "          loss = loss_fn(y_pred, y_batch.squeeze().cuda())\n",
    "          loss.backward()\n",
    "          optimiser.step()\n",
    "          optimiser.zero_grad()\n",
    "      if print_metrics:\n",
    "          losses_sum = 0.0 \n",
    "          model.eval()\n",
    "          with torch.no_grad():\n",
    "              for X_batch, y_batch in val_dl: \n",
    "                  y_pred = model(X_batch.cuda())\n",
    "                  losses_sum+=loss_fn(y_pred, y_batch.squeeze().cuda())\n",
    "              print(\n",
    "                  f\"Epoch {epoch}: \"\n",
    "                  f\"train loss = {loss:.3f} \"\n",
    "                  f\"validation loss = {losses_sum/len(val_dl):.3f}\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "CCBLeFRtfid9",
    "outputId": "98258ae5-1cf5-4fa2-d266-964ede226827"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss = 0.954 validation loss = 0.943\n",
      "Epoch 1: train loss = 0.961 validation loss = 0.946\n",
      "Epoch 2: train loss = 0.927 validation loss = 0.897\n",
      "Epoch 3: train loss = 0.900 validation loss = 0.875\n",
      "Epoch 4: train loss = 0.879 validation loss = 0.868\n",
      "Epoch 5: train loss = 0.872 validation loss = 0.852\n",
      "Epoch 6: train loss = 0.852 validation loss = 0.877\n",
      "Epoch 7: train loss = 0.850 validation loss = 0.880\n",
      "Epoch 8: train loss = 0.817 validation loss = 0.863\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2c79281a60d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0msentiment_test_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mprint_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-8-86dd3d01e9fc>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, optimiser, loss_fn, train_dl, val_dl, epochs, print_metrics)\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m               \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                   \u001b[0mlosses_sum\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m               print(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets_folder_path = os.path.join('tweeteval', 'datasets')\n",
    "sentiment_train_dl = read_to_dataloader(os.path.join(datasets_folder_path, 'sentiment'), batch_size, 'train')\n",
    "sentiment_test_dl = read_to_dataloader(os.path.join(datasets_folder_path, 'sentiment'), batch_size, 'test')\n",
    "\n",
    "output_size = 3\n",
    "hidden_size = 128\n",
    "num_layers = 4\n",
    "lr=0.001\n",
    "epochs = 50\n",
    "\n",
    "sentiment_model = LSTMModel(20, hidden_size, num_layers, output_size).cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(sentiment_model.parameters(), lr=lr)\n",
    "\n",
    "fit(\n",
    "    sentiment_model, \n",
    "    optim,\n",
    "    loss_fn, \n",
    "    sentiment_train_dl,\n",
    "    sentiment_test_dl,\n",
    "    epochs, \n",
    "    print_metrics = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636
    },
    "id": "LUcAI-LVhRbs",
    "outputId": "5c0bb8e7-9801-4cd4-865a-18e9d9fdc1d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss = 2.821 validation loss = 2.756\n",
      "Epoch 1: train loss = 2.819 validation loss = 2.755\n",
      "Epoch 2: train loss = 2.821 validation loss = 2.755\n",
      "Epoch 3: train loss = 2.604 validation loss = 2.499\n",
      "Epoch 4: train loss = 2.496 validation loss = 2.446\n",
      "Epoch 5: train loss = 2.482 validation loss = 2.401\n",
      "Epoch 6: train loss = 2.478 validation loss = 2.387\n",
      "Epoch 7: train loss = 2.475 validation loss = 2.376\n",
      "Epoch 8: train loss = 2.462 validation loss = 2.373\n",
      "Epoch 9: train loss = 2.466 validation loss = 2.375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-036ba82562d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0memoji_test_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mprint_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-8-86dd3d01e9fc>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, optimiser, loss_fn, train_dl, val_dl, epochs, print_metrics)\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emoji_train_dl = read_to_dataloader(os.path.join(datasets_folder_path, 'emoji'), batch_size, 'train')\n",
    "emoji_test_dl = read_to_dataloader(os.path.join(datasets_folder_path, 'emoji'), batch_size, 'test')\n",
    "\n",
    "output_size = 20\n",
    "hidden_size = 32\n",
    "num_layers = 4\n",
    "lr=0.001\n",
    "epochs = 50\n",
    "\n",
    "emoji_model = LSTMModel(20, hidden_size, num_layers, output_size).cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(emoji_model.parameters(), lr=lr)\n",
    "\n",
    "fit(\n",
    "    emoji_model, \n",
    "    optim,\n",
    "    loss_fn, \n",
    "    emoji_train_dl,\n",
    "    emoji_test_dl,\n",
    "    epochs, \n",
    "    print_metrics = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvy1SbHQ-lFs"
   },
   "source": [
    "## Trenowanie modeli LR (fastText) dla ZJAWISKO_1 i ZJAWISKO_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iWZe1B5R8GXQ"
   },
   "outputs": [],
   "source": [
    "!sed 's/^/__label__/g' tweeteval/datasets/sentiment/train_labels.txt > train_labels_sen.txt\n",
    "!sed 's/^/__label__/g' tweeteval/datasets/sentiment/test_labels.txt > test_labels_sen.txt\n",
    "!sed 's/^/__label__/g' tweeteval/datasets/sentiment/val_labels.txt > val_labels_sen.txt\n",
    "\n",
    "!paste -d \" \" tweeteval/datasets/sentiment/train_text.txt train_labels_sen.txt > train_sen.txt\n",
    "!paste -d \" \" tweeteval/datasets/sentiment/test_text.txt test_labels_sen.txt > test_sen.txt\n",
    "!paste -d \" \" tweeteval/datasets/sentiment/val_text.txt val_labels_sen.txt > val_sen.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3snucywJ8Ko9"
   },
   "outputs": [],
   "source": [
    "!sed 's/^/__label__/g' tweeteval/datasets/emoji/train_labels.txt > train_labels_emoji.txt\n",
    "!sed 's/^/__label__/g' tweeteval/datasets/emoji/test_labels.txt > test_labels_emoji.txt\n",
    "!sed 's/^/__label__/g' tweeteval/datasets/emoji/val_labels.txt > val_labels_emoji.txt\n",
    "\n",
    "!paste -d \" \" tweeteval/datasets/emoji/train_text.txt train_labels_emoji.txt > train_emoji.txt\n",
    "!paste -d \" \" tweeteval/datasets/emoji/test_text.txt test_labels_emoji.txt > test_emoji.txt\n",
    "!paste -d \" \" tweeteval/datasets/emoji/val_text.txt val_labels_emoji.txt > val_emoji.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0V4g2jmv-weV",
    "outputId": "8bfaf5a7-d9f8-41e8-ae31-1f633c6d617b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : dim is manually set to a specific value. It will not be automatically optimized.\n",
      "Progress: 100.0% Trials:   14 Best score:  0.696500 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 0M words\n",
      "Number of words:  106361\n",
      "Number of labels: 3\n",
      "Progress: 100.0% words/sec/thread:   66940 lr:  0.000000 avg.loss:  0.589642 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "!fasttext supervised -input train_sen.txt -output sen_model -dim 20 -pretrainedVectors fasttext_tweetmodel_btc_sg_20_en.vec -autotune-validation val_sen.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2FpG6Km_msZ",
    "outputId": "252b88ef-6f87-4006-90a5-52beb0b27919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : dim is manually set to a specific value. It will not be automatically optimized.\n",
      "Progress: 100.0% Trials:   17 Best score:  0.254000 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 0M words\n",
      "Number of words:  94918\n",
      "Number of labels: 20\n",
      "Progress: 100.0% words/sec/thread:  267616 lr:  0.000000 avg.loss:  1.891987 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "!fasttext supervised -input train_emoji.txt -output emoji_model -dim 20 -pretrainedVectors fasttext_tweetmodel_btc_sg_20_en.vec -autotune-validation val_emoji.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8neBnDzU-4o9"
   },
   "source": [
    "## Ewaluacja modeli na danych testowych dla zjawiska ZJAWISKO_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jJmFrD6VIo9d"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('predictions_LSTM'):\n",
    "  os.mkdir('predictions_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7wkbdG93_FxE"
   },
   "outputs": [],
   "source": [
    "sentiment_model.eval()\n",
    "y_pred_all = []\n",
    "for t_inp, _ in sentiment_test_dl:\n",
    "    t_inp = t_inp.cuda()\n",
    "    for x in sentiment_model(t_inp):\n",
    "        y_pred_all.append(torch.argmax(x).cpu().numpy().tolist())\n",
    "\n",
    "np.savetxt('predictions_LSTM/sentiment.txt', y_pred_all, fmt=\"%i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwL4ZNgvEjVR",
    "outputId": "94129aaf-13a8-401f-b114-92ff664b3bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'precision': 0.7607305936073059, 'recall': 0.20971802618328297, 'f1-score': 0.32879415827906056, 'support': 3972}\n",
      "1 {'precision': 0.5642701525054467, 'recall': 0.8288697995620684, 'f1-score': 0.6714422158548232, 'support': 5937}\n",
      "2 {'precision': 0.5405186385737439, 'recall': 0.5616842105263158, 'f1-score': 0.5508982035928144, 'support': 2375}\n",
      "accuracy 0.5770107456854445\n",
      "macro avg {'precision': 0.6218397948954989, 'recall': 0.5334240120905557, 'f1-score': 0.5170448592422328, 'support': 12284}\n",
      "weighted avg {'precision': 0.6232029941261558, 'recall': 0.5770107456854445, 'f1-score': 0.537341750712101, 'support': 12284}\n",
      "------------------------------\n",
      "TweetEval Score (sentiment): 0.5334240120905557\n"
     ]
    }
   ],
   "source": [
    "!python tweeteval/evaluation_script.py --tweeteval_path tweeteval/datasets --predictions_path predictions_LSTM --task sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "86nqNMbGJXjy"
   },
   "outputs": [],
   "source": [
    "!fasttext predict sen_model.bin tweeteval/datasets/sentiment/test_text.txt | sed 's/__label__//g' > predictions2/sentiment.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2aaP5fS_JiQT",
    "outputId": "357bf309-1fb1-47ab-bc2c-dfc04d4df09b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'precision': 0.6505515898767035, 'recall': 0.5047834843907352, 'f1-score': 0.5684717890558549, 'support': 3972}\n",
      "1 {'precision': 0.6256402297066583, 'recall': 0.6789624389422267, 'f1-score': 0.6512116316639741, 'support': 5937}\n",
      "2 {'precision': 0.5498368974266038, 'recall': 0.6387368421052632, 'f1-score': 0.5909622126996493, 'support': 2375}\n",
      "accuracy 0.6148648648648649\n",
      "macro avg {'precision': 0.6086762390033219, 'recall': 0.607494255146075, 'f1-score': 0.6035485444731594, 'support': 12284}\n",
      "weighted avg {'precision': 0.6190393674818366, 'recall': 0.6148648648648649, 'f1-score': 0.6128092362813853, 'support': 12284}\n",
      "------------------------------\n",
      "TweetEval Score (sentiment): 0.607494255146075\n"
     ]
    }
   ],
   "source": [
    "!python tweeteval/evaluation_script.py --tweeteval_path tweeteval/datasets --predictions_path predictions2 --task sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIHyGqMM_HaE"
   },
   "source": [
    "## Ewaluacja modeli na danych testowych dla zjawiska ZJAWISKO_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "MQ8yTGuu_Ird"
   },
   "outputs": [],
   "source": [
    "emoji_model.eval()\n",
    "y_pred_all = []\n",
    "for t_inp, _ in emoji_test_dl:\n",
    "    t_inp = t_inp.cuda()\n",
    "    for x in emoji_model(t_inp):\n",
    "        y_pred_all.append(torch.argmax(x).cpu().numpy().tolist())\n",
    "\n",
    "np.savetxt('predictions_LSTM/emoji.txt', y_pred_all, fmt=\"%i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lOSBIRfK8cH",
    "outputId": "f1cbfbb5-0c24-4f30-93a7-5b52dc13f90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "0 {'precision': 0.7766925848663, 'recall': 0.7585664011854047, 'f1-score': 0.7675224887556221, 'support': 10798}\n",
      "1 {'precision': 0.1246473840598789, 'recall': 0.686128364389234, 'f1-score': 0.21096858388770415, 'support': 4830}\n",
      "10 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1432}\n",
      "11 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1949}\n",
      "12 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1265}\n",
      "13 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1114}\n",
      "14 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1306}\n",
      "15 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1244}\n",
      "16 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1153}\n",
      "17 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1545}\n",
      "18 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2417}\n",
      "19 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1010}\n",
      "2 {'precision': 0.21559026968213257, 'recall': 0.611821790913101, 'f1-score': 0.3188322510200563, 'support': 4534}\n",
      "3 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2605}\n",
      "4 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3716}\n",
      "5 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1613}\n",
      "6 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1996}\n",
      "7 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2749}\n",
      "8 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1549}\n",
      "9 {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1175}\n",
      "accuracy 0.28558\n",
      "macro avg {'precision': 0.055846511930415565, 'recall': 0.10282582782438698, 'f1-score': 0.06486616618316912, 'support': 50000}\n",
      "weighted avg {'precision': 0.19932519358268627, 'recall': 0.28558, 'f1-score': 0.2150454303977151, 'support': 50000}\n",
      "------------------------------\n",
      "TweetEval Score (emoji): 0.06486616618316912\n"
     ]
    }
   ],
   "source": [
    "!python tweeteval/evaluation_script.py --tweeteval_path tweeteval/datasets --predictions_path predictions_LSTM --task emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "CXyLA3gDLOJ-"
   },
   "outputs": [],
   "source": [
    "!fasttext predict emoji_model.bin tweeteval/datasets/emoji/test_text.txt | sed 's/__label__//g' > predictions2/emoji.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zm3PAO-lLafS",
    "outputId": "4a7f0e14-e1bc-4aaf-b00d-5b913ac129a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'precision': 0.726998491704374, 'recall': 0.7588442304130395, 'f1-score': 0.7425800897186098, 'support': 10798}\n",
      "1 {'precision': 0.22086314331871681, 'recall': 0.39627329192546584, 'f1-score': 0.2836395969176052, 'support': 4830}\n",
      "10 {'precision': 0.2691194708557255, 'recall': 0.454608938547486, 'f1-score': 0.3380940015580369, 'support': 1432}\n",
      "11 {'precision': 0.41211401425178146, 'recall': 0.3560800410466906, 'f1-score': 0.38205339939443983, 'support': 1949}\n",
      "12 {'precision': 0.4825090470446321, 'recall': 0.31620553359683795, 'f1-score': 0.3820439350525311, 'support': 1265}\n",
      "13 {'precision': 0.034482758620689655, 'recall': 0.0026929982046678637, 'f1-score': 0.004995836802664447, 'support': 1114}\n",
      "14 {'precision': 0.09671179883945841, 'recall': 0.03828483920367534, 'f1-score': 0.0548546352166758, 'support': 1306}\n",
      "15 {'precision': 0.15011547344110854, 'recall': 0.0522508038585209, 'f1-score': 0.07751937984496124, 'support': 1244}\n",
      "16 {'precision': 0.06208053691275168, 'recall': 0.032090199479618386, 'f1-score': 0.042309891366495135, 'support': 1153}\n",
      "17 {'precision': 0.5780141843971631, 'recall': 0.5275080906148867, 'f1-score': 0.5516074450084603, 'support': 1545}\n",
      "18 {'precision': 0.3516339869281046, 'recall': 0.11129499379395945, 'f1-score': 0.169076052796983, 'support': 2417}\n",
      "19 {'precision': 0.04225352112676056, 'recall': 0.005940594059405941, 'f1-score': 0.010416666666666668, 'support': 1010}\n",
      "2 {'precision': 0.29533224877987735, 'recall': 0.5205116894574328, 'f1-score': 0.3768463073852295, 'support': 4534}\n",
      "3 {'precision': 0.19646125686394142, 'recall': 0.1236084452975048, 'f1-score': 0.15174363807728558, 'support': 2605}\n",
      "4 {'precision': 0.4189542483660131, 'recall': 0.344994617868676, 'f1-score': 0.3783943329397875, 'support': 3716}\n",
      "5 {'precision': 0.09383145091225022, 'recall': 0.13391196528208307, 'f1-score': 0.1103448275862069, 'support': 1613}\n",
      "6 {'precision': 0.12827058072750477, 'recall': 0.10070140280561123, 'f1-score': 0.11282626999719338, 'support': 1996}\n",
      "7 {'precision': 0.2054120541205412, 'recall': 0.242997453619498, 'f1-score': 0.22262956173971005, 'support': 2749}\n",
      "8 {'precision': 0.14627659574468085, 'recall': 0.035506778566817304, 'f1-score': 0.05714285714285715, 'support': 1549}\n",
      "9 {'precision': 0.10663983903420524, 'recall': 0.0902127659574468, 'f1-score': 0.09774089442139235, 'support': 1175}\n",
      "accuracy 0.36616\n",
      "macro avg {'precision': 0.25090373509951397, 'recall': 0.23222598367996622, 'f1-score': 0.2273429809816896, 'support': 50000}\n",
      "weighted avg {'precision': 0.35312206690367753, 'recall': 0.36616, 'f1-score': 0.34645668059409024, 'support': 50000}\n",
      "------------------------------\n",
      "TweetEval Score (emoji): 0.2273429809816896\n"
     ]
    }
   ],
   "source": [
    "!python tweeteval/evaluation_script.py --tweeteval_path tweeteval/datasets --predictions_path predictions2 --task emoji"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab09.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
